Once the pipeline is deployed, now it's time to evaluate the model. 

Invoke the service using:  http://<host>:<port>/api/ml/evaluate/<servicename>

Example:
```
http://localhost:5555/api/ml/evaluate/housing
```

Calling this service triggers a background process since some of the model evaluation like deep learning models takes time to complete the training process. 
The output of the service will be a jobid which you can use to check the status of the job.